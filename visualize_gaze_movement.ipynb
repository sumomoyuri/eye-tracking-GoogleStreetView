{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import csv\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime as dt\n",
    "from tqdm import tqdm\n",
    "import moviepy.editor as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "#視線データの読み込み\n",
    "######################\n",
    "\n",
    "#視線生データ\n",
    "gaze_data = \"output/output_gaze.csv\"\n",
    "\n",
    "# csvを一行づつ読み込み視線データをdictに格納\n",
    "gp_dict={} #注視点格納用dictionary\n",
    "with open(gaze_data) as f: #生データ\n",
    "    for df in csv.reader(f):\n",
    "        if df == []:\n",
    "            continue\n",
    "        row = [df[0],df[1],df[2],df[3],df[4]\n",
    "        #データの欠損状況で場合分け\n",
    "        if row[1] != 'nan' and row[3] != 'nan':\n",
    "            x = (float(row[1])+float(row[3]))/2\n",
    "            y = (float(row[2])+float(row[4]))/2\n",
    "        elif row[1] != 'nan' and row[3] == 'nan':\n",
    "            x = float(row[1])\n",
    "            y = float(row[2])\n",
    "        elif row[1] == 'nan' and row[3] != 'nan':\n",
    "            x = float(row[3])\n",
    "            y = float(row[4])\n",
    "        else: #全欠損の場合は−１とする\n",
    "            x = -1\n",
    "            y = -1\n",
    "        #時刻が'17:53:09'のように秒以下が無い(.000000になっている)時は.000000を文字列に追加。\n",
    "        if len(row[0]) == 19:\n",
    "            row[0] = row[0] + '.000000'\n",
    "        gaze_time = dt.datetime.strptime(row[0], '%Y-%m-%d %H:%M:%S.%f') #文字列を時刻に変換 #https://techacademy.jp/magazine/23375\n",
    "        gp_dict[gaze_time] = [x,y] #時刻をkey、注視点座標をvalueに\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "#画面録画の動画読み込み\n",
    "######################\n",
    "\n",
    "# 画面録画の動画（インプット）\n",
    "video = \"output/screen_record.mp4\"\n",
    "\n",
    "# 動画の開始時刻 （XXXに時刻を入力）\n",
    "start_time = dt.datetime.strptime('XXXX-XX-XX XX:XX:XX.XXXXXX', '%Y-%m-%d %H:%M:%S.%f')\n",
    "\n",
    "#動画の読み込み\n",
    "cap = cv2.VideoCapture(video)\n",
    "\n",
    "#動画の情報\n",
    "video_w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))# 幅\n",
    "video_h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))# 高さ\n",
    "count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))# 総フレーム数\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)# フレームレート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "#動画と注視点を時刻で突き合わせて出力\n",
    "######################\n",
    "\n",
    "# 注視点を追加した出力動画（アウトプット）\n",
    "result = \"output/gaze_movement.mp4\"\n",
    "\n",
    "#出力動画の形式\n",
    "fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')\n",
    "output = cv2.VideoWriter( result, fourcc, 30, (int(video_w), int(video_h)))\n",
    "\n",
    "# 描画用パラメータ\n",
    "r = 30 #円の半径\n",
    "screen_w = 1920\n",
    "screen_h = 1080\n",
    "\n",
    "#動画への注視点の描画\n",
    "video_time = start_time\n",
    "for i in range(count):\n",
    "    ret, frame_ = cap.read()# 動画から1フレーム取得する\n",
    "    if ret:\n",
    "        # リサイズ\n",
    "        frame = cv2.resize(frame_, (int(video_w), int(video_h)))\n",
    "        \n",
    "        # video_timeに最も近い時刻の注視点(x,y)を取得\n",
    "        gaze_point = gp_dict[min(gp_dict.keys(), key = lambda k: abs(k - video_time))]\n",
    "        \n",
    "        if gaze_point[0] != -1: #視線位置が欠損していなければ注視点を描画\n",
    "            x = int(screen_w * zoom * gaze_point[0])\n",
    "            y = int(screen_h * zoom *  gaze_point[1])\n",
    "            cv2.circle(frame,(x, y), r, (0, 0, 255), int(5 * zoom))\n",
    "\n",
    "        # 時刻を描画\n",
    "        cv2.putText(frame, str(video_time), (0, 30), cv２.FONT_HERSHEY_PLAIN, 1, (0, 0, 255), 1, cv２.LINE_AA)\n",
    "        \n",
    "        #フレームを.mp4に出力\n",
    "        output.write(frame) \n",
    "        #1フレーム分時刻を進める\n",
    "        video_time = video_time + dt.timedelta(microseconds = 1000000/fps)\n",
    "            \n",
    "    else:\n",
    "        break  \n",
    "        \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): #[q]キーを押して処理を中断。\n",
    "        break\n",
    "            \n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aJ8O8FZbEJTf"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOCQKCaRGlHRQrGWmcJnUD9",
   "collapsed_sections": [],
   "name": "動画可視化+音声結合.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
